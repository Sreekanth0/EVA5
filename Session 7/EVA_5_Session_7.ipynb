{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA 5 Session 7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f48fd3b1ef64eed8fdf52436678bb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f46c8476595449629f72ea85781bbafa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_047291d51fb84c27b212cd01c7d1883a",
              "IPY_MODEL_7487883e0bff4eada21cfda8e152d758"
            ]
          }
        },
        "f46c8476595449629f72ea85781bbafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "047291d51fb84c27b212cd01c7d1883a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75204332031b4a73b3afe12cc662d89f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e4240a61f94d8180f77ae0576a6770"
          }
        },
        "7487883e0bff4eada21cfda8e152d758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b29213edc894c80bdfaa7e5ba55ee1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 30627776.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75d84e582dd24b42891b4ec5ec4ae2c5"
          }
        },
        "75204332031b4a73b3afe12cc662d89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e4240a61f94d8180f77ae0576a6770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b29213edc894c80bdfaa7e5ba55ee1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75d84e582dd24b42891b4ec5ec4ae2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWQTEUL1r5Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "5d05ccd6-c1f3-431a-af37-0656b2c5e608"
      },
      "source": [
        "!pip install git+https://github.com/firekind/athena@v0.0.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/firekind/athena@v0.0.1\n",
            "  Cloning https://github.com/firekind/athena (to revision v0.0.1) to /tmp/pip-req-build-aph08_ay\n",
            "  Running command git clone -q https://github.com/firekind/athena /tmp/pip-req-build-aph08_ay\n",
            "  Running command git checkout -q 76f26a105635a8dedade28cf37be0c051bd5ddc4\n",
            "Requirement already satisfied (use --upgrade to upgrade): athena==0.0.1 from git+https://github.com/firekind/athena@v0.0.1 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (from athena==0.0.1) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from athena==0.0.1) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from athena==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from athena==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->athena==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->athena==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->athena==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->athena==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->athena==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (50.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->athena==0.0.1) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->athena==0.0.1) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->athena==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->athena==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->athena==0.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->athena==0.0.1) (2020.6.20)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->athena==0.0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->athena==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->athena==0.0.1) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->athena==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->athena==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->athena==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->athena==0.0.1) (3.1.0)\n",
            "Building wheels for collected packages: athena\n",
            "  Building wheel for athena (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for athena: filename=athena-0.0.1-cp36-none-any.whl size=29405 sha256=cd54c121718a54f67c961eb559d175afb5f1e8f6c853bf3f49a0bd36490d8cc8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f419hh7f/wheels/c6/98/d8/85f5f37d92af24edb6c8b143a23751e6034a2c173665356fed\n",
            "Successfully built athena\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR1I4S6rsF54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from athena import datasets, Experiment, ClassificationSolver"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zijb7LtdHsML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Importing My Model\n",
        "from athena.models import cifar10_v2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28-Ht-upsGZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFCjlE5sI8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d5502b2-84c7-4e19-cc0a-6919c7507726"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHPMxpcasKyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "6f48fd3b1ef64eed8fdf52436678bb3a",
            "f46c8476595449629f72ea85781bbafa",
            "047291d51fb84c27b212cd01c7d1883a",
            "7487883e0bff4eada21cfda8e152d758",
            "75204332031b4a73b3afe12cc662d89f",
            "42e4240a61f94d8180f77ae0576a6770",
            "4b29213edc894c80bdfaa7e5ba55ee1e",
            "75d84e582dd24b42891b4ec5ec4ae2c5"
          ]
        },
        "outputId": "daed0841-28bb-4cb6-e97b-fa564b1f1dec"
      },
      "source": [
        "batch_size = 128 if device == 'cuda' else 64\n",
        "\n",
        "train_loader = datasets.cifar10(download=True, batch_size=batch_size, use_default_transforms=True)\n",
        "test_loader = datasets.cifar10(train=False, download=True, batch_size=batch_size, use_default_transforms=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f48fd3b1ef64eed8fdf52436678bb3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb7_2GzisMYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c27a6880-2625-4de9-8753-1d57289c2c2c"
      },
      "source": [
        "net = cifar10_v2.Cifar10V2().to(device)\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]             288\n",
            "            Conv2d-6           [-1, 32, 32, 32]           1,056\n",
            "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
            "              ReLU-8           [-1, 32, 32, 32]               0\n",
            "           Dropout-9           [-1, 32, 32, 32]               0\n",
            "           Conv2d-10           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "             ReLU-12           [-1, 32, 32, 32]               0\n",
            "          Dropout-13           [-1, 32, 32, 32]               0\n",
            "           Conv2d-14           [-1, 32, 32, 32]             288\n",
            "           Conv2d-15           [-1, 32, 32, 32]           1,056\n",
            "      BatchNorm2d-16           [-1, 32, 32, 32]              64\n",
            "             ReLU-17           [-1, 32, 32, 32]               0\n",
            "          Dropout-18           [-1, 32, 32, 32]               0\n",
            "           Conv2d-19           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
            "             ReLU-21           [-1, 64, 16, 16]               0\n",
            "          Dropout-22           [-1, 64, 16, 16]               0\n",
            "           Conv2d-23           [-1, 64, 16, 16]             576\n",
            "           Conv2d-24           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-25           [-1, 64, 16, 16]             128\n",
            "             ReLU-26           [-1, 64, 16, 16]               0\n",
            "          Dropout-27           [-1, 64, 16, 16]               0\n",
            "           Conv2d-28           [-1, 64, 16, 16]             576\n",
            "           Conv2d-29           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
            "             ReLU-31           [-1, 64, 16, 16]               0\n",
            "          Dropout-32           [-1, 64, 16, 16]               0\n",
            "           Conv2d-33           [-1, 64, 16, 16]             576\n",
            "           Conv2d-34           [-1, 64, 16, 16]           4,160\n",
            "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
            "             ReLU-36           [-1, 64, 16, 16]               0\n",
            "          Dropout-37           [-1, 64, 16, 16]               0\n",
            "           Conv2d-38            [-1, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-39            [-1, 128, 8, 8]             256\n",
            "             ReLU-40            [-1, 128, 8, 8]               0\n",
            "          Dropout-41            [-1, 128, 8, 8]               0\n",
            "           Conv2d-42            [-1, 128, 8, 8]           1,152\n",
            "           Conv2d-43            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-44            [-1, 128, 8, 8]             256\n",
            "             ReLU-45            [-1, 128, 8, 8]               0\n",
            "          Dropout-46            [-1, 128, 8, 8]               0\n",
            "           Conv2d-47            [-1, 128, 8, 8]           1,152\n",
            "           Conv2d-48            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-49            [-1, 128, 8, 8]             256\n",
            "             ReLU-50            [-1, 128, 8, 8]               0\n",
            "          Dropout-51            [-1, 128, 8, 8]               0\n",
            "           Conv2d-52            [-1, 128, 8, 8]           1,152\n",
            "           Conv2d-53            [-1, 128, 8, 8]          16,512\n",
            "      BatchNorm2d-54            [-1, 128, 8, 8]             256\n",
            "             ReLU-55            [-1, 128, 8, 8]               0\n",
            "          Dropout-56            [-1, 128, 8, 8]               0\n",
            "           Conv2d-57            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-58            [-1, 256, 8, 8]             512\n",
            "             ReLU-59            [-1, 256, 8, 8]               0\n",
            "          Dropout-60            [-1, 256, 8, 8]               0\n",
            "           Conv2d-61            [-1, 256, 8, 8]           2,304\n",
            "           Conv2d-62            [-1, 256, 8, 8]          65,792\n",
            "      BatchNorm2d-63            [-1, 256, 8, 8]             512\n",
            "             ReLU-64            [-1, 256, 8, 8]               0\n",
            "          Dropout-65            [-1, 256, 8, 8]               0\n",
            "           Conv2d-66            [-1, 256, 8, 8]           2,304\n",
            "           Conv2d-67            [-1, 256, 8, 8]          65,792\n",
            "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
            "             ReLU-69            [-1, 256, 8, 8]               0\n",
            "          Dropout-70            [-1, 256, 8, 8]               0\n",
            "           Conv2d-71            [-1, 256, 8, 8]           2,304\n",
            "           Conv2d-72            [-1, 256, 8, 8]          65,792\n",
            "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
            "             ReLU-74            [-1, 256, 8, 8]               0\n",
            "          Dropout-75            [-1, 256, 8, 8]               0\n",
            "        AvgPool2d-76            [-1, 256, 1, 1]               0\n",
            "           Linear-77                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 677,738\n",
            "Trainable params: 677,738\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.44\n",
            "Params size (MB): 2.59\n",
            "Estimated Total Size (MB): 13.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-gRcDklsUzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=8, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dFjVRE2sbq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def l1_loss(l1_lambda):\n",
        "    def _l1_loss(y_pred, target):\n",
        "        loss = F.nll_loss(y_pred, target)\n",
        "        l1 = 0\n",
        "        for p in model.parameters():\n",
        "            l1 = l1 + p.abs().sum()\n",
        "        loss = loss + l1_lambda * l1\n",
        "        return loss\n",
        "\n",
        "    return _l1_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY1Yfjknsdq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed4d26ab-c2af-4d2f-e6fd-19236782fb9b"
      },
      "source": [
        "l1_lambda = 5e-4\n",
        "exp = Experiment(\n",
        "    name=\"New Model\",\n",
        "    model=model,\n",
        "    solver_cls=ClassificationSolver,\n",
        "    train_args=dict(\n",
        "        epochs=50,\n",
        "        train_loader=trainloader,\n",
        "        test_loader=testloader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        loss_fn=l1_loss(l1_lambda),\n",
        "    )\n",
        ")\n",
        "\n",
        "exp.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[92m=> Running experiment: New Model\u001b[0m\n",
            "Epoch: 1 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 9.2793 - accuracy: 27.8140\n",
            "Test set: Average loss: 9.4941, Accuracy: 3366/10000 (33.66%)\n",
            "\n",
            "Epoch: 2 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 6.8643 - accuracy: 44.3760\n",
            "Test set: Average loss: 7.3521, Accuracy: 4935/10000 (49.35%)\n",
            "\n",
            "Epoch: 3 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 5.8407 - accuracy: 54.0560\n",
            "Test set: Average loss: 5.8899, Accuracy: 5617/10000 (56.17%)\n",
            "\n",
            "Epoch: 4 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 5.2328 - accuracy: 59.8400\n",
            "Test set: Average loss: 5.0300, Accuracy: 5901/10000 (59.01%)\n",
            "\n",
            "Epoch: 5 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 4.2297 - accuracy: 62.8760\n",
            "Test set: Average loss: 4.2838, Accuracy: 6595/10000 (65.95%)\n",
            "\n",
            "Epoch: 6 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 4.0412 - accuracy: 65.3380\n",
            "Test set: Average loss: 3.7885, Accuracy: 6886/10000 (68.86%)\n",
            "\n",
            "Epoch: 7 / 50\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 3.3914 - accuracy: 67.2520\n",
            "Test set: Average loss: 3.5615, Accuracy: 6738/10000 (67.38%)\n",
            "\n",
            "Epoch: 8 / 50\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 3.6070 - accuracy: 68.5540\n",
            "Test set: Average loss: 3.3293, Accuracy: 6953/10000 (69.53%)\n",
            "\n",
            "Epoch: 9 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.9232 - accuracy: 75.1860\n",
            "Test set: Average loss: 2.9633, Accuracy: 7897/10000 (78.97%)\n",
            "\n",
            "Epoch: 10 / 50\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 3.0492 - accuracy: 76.7700\n",
            "Test set: Average loss: 2.9010, Accuracy: 8005/10000 (80.05%)\n",
            "\n",
            "Epoch: 11 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.8744 - accuracy: 77.1020\n",
            "Test set: Average loss: 2.8634, Accuracy: 7982/10000 (79.82%)\n",
            "\n",
            "Epoch: 12 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 3.1870 - accuracy: 77.4800\n",
            "Test set: Average loss: 2.8194, Accuracy: 8050/10000 (80.50%)\n",
            "\n",
            "Epoch: 13 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.6540 - accuracy: 77.9800\n",
            "Test set: Average loss: 2.7868, Accuracy: 8085/10000 (80.85%)\n",
            "\n",
            "Epoch: 14 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0573 - accuracy: 78.0640\n",
            "Test set: Average loss: 2.7700, Accuracy: 8082/10000 (80.82%)\n",
            "\n",
            "Epoch: 15 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 3.3045 - accuracy: 78.2220\n",
            "Test set: Average loss: 2.7495, Accuracy: 8100/10000 (81.00%)\n",
            "\n",
            "Epoch: 16 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.8771 - accuracy: 78.4640\n",
            "Test set: Average loss: 2.7510, Accuracy: 8028/10000 (80.28%)\n",
            "\n",
            "Epoch: 17 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.8297 - accuracy: 79.6700\n",
            "Test set: Average loss: 2.6994, Accuracy: 8177/10000 (81.77%)\n",
            "\n",
            "Epoch: 18 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.5333 - accuracy: 80.4880\n",
            "Test set: Average loss: 2.6912, Accuracy: 8184/10000 (81.84%)\n",
            "\n",
            "Epoch: 19 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.9177 - accuracy: 80.5000\n",
            "Test set: Average loss: 2.6786, Accuracy: 8202/10000 (82.02%)\n",
            "\n",
            "Epoch: 20 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.5335 - accuracy: 80.6660\n",
            "Test set: Average loss: 2.6635, Accuracy: 8232/10000 (82.32%)\n",
            "\n",
            "Epoch: 21 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.7637 - accuracy: 80.8340\n",
            "Test set: Average loss: 2.6597, Accuracy: 8236/10000 (82.36%)\n",
            "\n",
            "Epoch: 22 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.5850 - accuracy: 80.8040\n",
            "Test set: Average loss: 2.6574, Accuracy: 8224/10000 (82.24%)\n",
            "\n",
            "Epoch: 23 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.6253 - accuracy: 80.8080\n",
            "Test set: Average loss: 2.6464, Accuracy: 8251/10000 (82.51%)\n",
            "\n",
            "Epoch: 24 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 3.1522 - accuracy: 80.8880\n",
            "Test set: Average loss: 2.6410, Accuracy: 8258/10000 (82.58%)\n",
            "\n",
            "Epoch: 25 / 50\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 2.6733 - accuracy: 81.0600\n",
            "Test set: Average loss: 2.6418, Accuracy: 8244/10000 (82.44%)\n",
            "\n",
            "Epoch: 26 / 50\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 3.0471 - accuracy: 81.2380\n",
            "Test set: Average loss: 2.6356, Accuracy: 8249/10000 (82.49%)\n",
            "\n",
            "Epoch: 27 / 50\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 2.5745 - accuracy: 81.6300\n",
            "Test set: Average loss: 2.6386, Accuracy: 8248/10000 (82.48%)\n",
            "\n",
            "Epoch: 28 / 50\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 2.8885 - accuracy: 81.5440\n",
            "Test set: Average loss: 2.6313, Accuracy: 8282/10000 (82.82%)\n",
            "\n",
            "Epoch: 29 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8372 - accuracy: 81.4900\n",
            "Test set: Average loss: 2.6384, Accuracy: 8232/10000 (82.32%)\n",
            "\n",
            "Epoch: 30 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.7484 - accuracy: 81.3280\n",
            "Test set: Average loss: 2.6352, Accuracy: 8272/10000 (82.72%)\n",
            "\n",
            "Epoch: 31 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8087 - accuracy: 81.2520\n",
            "Test set: Average loss: 2.6385, Accuracy: 8256/10000 (82.56%)\n",
            "\n",
            "Epoch: 32 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.6286 - accuracy: 81.4580\n",
            "Test set: Average loss: 2.6425, Accuracy: 8229/10000 (82.29%)\n",
            "\n",
            "Epoch: 33 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8611 - accuracy: 81.3400\n",
            "Test set: Average loss: 2.6354, Accuracy: 8263/10000 (82.63%)\n",
            "\n",
            "Epoch: 34 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.5863 - accuracy: 81.3300\n",
            "Test set: Average loss: 2.6348, Accuracy: 8258/10000 (82.58%)\n",
            "\n",
            "Epoch: 35 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.7813 - accuracy: 81.5520\n",
            "Test set: Average loss: 2.6282, Accuracy: 8289/10000 (82.89%)\n",
            "\n",
            "Epoch: 36 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8290 - accuracy: 81.4340\n",
            "Test set: Average loss: 2.6283, Accuracy: 8277/10000 (82.77%)\n",
            "\n",
            "Epoch: 37 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.7616 - accuracy: 81.4640\n",
            "Test set: Average loss: 2.6267, Accuracy: 8275/10000 (82.75%)\n",
            "\n",
            "Epoch: 38 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.5016 - accuracy: 81.4240\n",
            "Test set: Average loss: 2.6396, Accuracy: 8222/10000 (82.22%)\n",
            "\n",
            "Epoch: 39 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 3.0498 - accuracy: 81.4620\n",
            "Test set: Average loss: 2.6287, Accuracy: 8274/10000 (82.74%)\n",
            "\n",
            "Epoch: 40 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.5869 - accuracy: 81.5740\n",
            "Test set: Average loss: 2.6407, Accuracy: 8236/10000 (82.36%)\n",
            "\n",
            "Epoch: 41 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.6333 - accuracy: 81.5940\n",
            "Test set: Average loss: 2.6296, Accuracy: 8284/10000 (82.84%)\n",
            "\n",
            "Epoch: 42 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.5538 - accuracy: 81.3160\n",
            "Test set: Average loss: 2.6320, Accuracy: 8257/10000 (82.57%)\n",
            "\n",
            "Epoch: 43 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.6282 - accuracy: 81.1780\n",
            "Test set: Average loss: 2.6308, Accuracy: 8259/10000 (82.59%)\n",
            "\n",
            "Epoch: 44 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8212 - accuracy: 81.4200\n",
            "Test set: Average loss: 2.6315, Accuracy: 8263/10000 (82.63%)\n",
            "\n",
            "Epoch: 45 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.8056 - accuracy: 81.4180\n",
            "Test set: Average loss: 2.6357, Accuracy: 8248/10000 (82.48%)\n",
            "\n",
            "Epoch: 46 / 50\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 2.4857 - accuracy: 81.3180\n",
            "Test set: Average loss: 2.6436, Accuracy: 8219/10000 (82.19%)\n",
            "\n",
            "Epoch: 47 / 50\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 2.5809 - accuracy: 81.2980\n",
            "Test set: Average loss: 2.6307, Accuracy: 8266/10000 (82.66%)\n",
            "\n",
            "Epoch: 48 / 50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 2.6140 - accuracy: 81.5560\n",
            "Test set: Average loss: 2.6267, Accuracy: 8283/10000 (82.83%)\n",
            "\n",
            "Epoch: 49 / 50\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 2.5519 - accuracy: 81.7700\n",
            "Test set: Average loss: 2.6258, Accuracy: 8289/10000 (82.89%)\n",
            "\n",
            "Epoch: 50 / 50\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 2.8191 - accuracy: 81.3540\n",
            "Test set: Average loss: 2.6276, Accuracy: 8276/10000 (82.76%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwZvZlGswOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}